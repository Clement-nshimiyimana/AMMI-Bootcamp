{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00_hBAXP9fze",
        "outputId": "89bb7c60-1686-4c6c-e728-7d33e18d6fee"
      },
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-geometric"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.0 MB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 222 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 376 kB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_D1o--F842O"
      },
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch \n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import torch.optim as optim\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import to_dense_adj"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1oE_p4r8jlV"
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class GraphConvolution(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    GCN layer\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, bias= True):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # dimension of the input features and output features\n",
        "\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.weight = None\n",
        "\n",
        "        # initialise the weight matrix\n",
        "\n",
        "        stdv = 1 / math.sqrt(self.out_features)\n",
        "\n",
        "        self.weight = torch.FloatTensor(in_features, out_features).uniform_(-stdv, stdv)\n",
        "\n",
        "        self.weight = nn.Parameter(self.weight, requires_grad=True)\n",
        "\n",
        "        if bias:\n",
        "            self.bias = torch.FloatTensor(out_features).uniform_(-stdv, stdv)\n",
        "            self.bias = nn.Parameter(self.bias, requires_grad=True)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "\n",
        "    def forward(self, fts, adj):\n",
        "\n",
        "        A_ = adj.to(device) + torch.eye(adj.shape[0]).to(device)\n",
        "        D_power_  = torch.diag(torch.pow(A_.sum(dim=-1),-0.5))\n",
        "        support = torch.mm(A_, D_power_)\n",
        "        support = torch.mm(D_power_, support)\n",
        "\n",
        "        output = torch.mm(fts, self.weight)\n",
        "    \n",
        "        output = torch.sparse.mm(support, output)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUKoWIXv9AFr"
      },
      "source": [
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
        "        super().__init__()\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nclass)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, fts, adj):\n",
        "        fts = F.relu(self.gc1(fts, adj))\n",
        "        fts = F.dropout(fts, self.dropout, training=self.training)\n",
        "        fts = self.gc2(fts, adj)\n",
        "        return F.log_softmax(fts, dim=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6yfIFr-85-e",
        "outputId": "f279ffce-6018-4e62-c85a-d20ba37e4f72"
      },
      "source": [
        "\n",
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train(model, data, num_epochs, use_edge_index=False):\n",
        "    if not use_edge_index:\n",
        "\n",
        "        # Create the adjacency matrix\n",
        "        adj = to_dense_adj(data.edge_index)[0]\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Directly use edge_index, ignore this branch for now\n",
        "        adj = data.edge_index\n",
        "        \n",
        "    model.to(device)\n",
        "    data.to(device)\n",
        "\n",
        "    # Set up the optimizer\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "    # A utility function to compute the accuracy\n",
        "    def get_acc(outs, y, mask):\n",
        "        return (outs[mask].argmax(dim=1) == y[mask]).sum().float() / mask.sum()\n",
        "\n",
        "    best_acc_val = -1\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Zero grads -> forward pass -> compute loss -> backprop\n",
        "        \n",
        "        # train mode\n",
        "        model.train()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outs = model(data.x.to(device), adj.to(device))\n",
        "\n",
        "        # null_loss \n",
        "\n",
        "        loss = F.nll_loss(outs[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracies, print only if this is the best result so far\n",
        "\n",
        "        # evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # data.x = the features of the dataset\n",
        "\n",
        "        outs = model(data.x, adj)\n",
        "\n",
        "        # validation accuracy \n",
        "        acc_val = get_acc(outs, data.y, data.val_mask)\n",
        "\n",
        "        # test accuracy \n",
        "        acc_test = get_acc(outs, data.y, data.test_mask)\n",
        "\n",
        "        # print the accuracy if it’s incresed\n",
        "        if acc_val > best_acc_val:\n",
        "            best_acc_val = acc_val\n",
        "            print(f'[Epoch {epoch+1}/{num_epochs}] Loss: {loss} | Val: {acc_val:.3f} | Test: {acc_test:.3f}')\n",
        "\n",
        "    print(f'[Epoch {epoch+1}/{num_epochs}] Loss: {loss} | Val: {acc_val:.3f} | Test: {acc_test:.3f}')\n",
        "    \n",
        "\n",
        "\n",
        "Cora = torch_geometric.datasets.Planetoid(root='/', name='Cora')\n",
        "\n",
        "Citeseer = torch_geometric.datasets.Planetoid(root='/', name='CiteSeer')\n",
        "\n",
        "Pubmed = torch_geometric.datasets.Planetoid(root='/', name='PubMed')\n",
        "        \n",
        "model_cora = GCN(nfeat = Cora.num_features, nhid = 16, nclass = Cora.num_classes, dropout = 0.5)\n",
        "\n",
        "train(model_cora, data = Cora[0] , num_epochs = 200)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n",
            "[Epoch 1/200] Loss: 1.9620481729507446 | Val: 0.210 | Test: 0.203\n",
            "[Epoch 2/200] Loss: 1.8468514680862427 | Val: 0.294 | Test: 0.266\n",
            "[Epoch 3/200] Loss: 1.7902510166168213 | Val: 0.360 | Test: 0.359\n",
            "[Epoch 4/200] Loss: 1.7073495388031006 | Val: 0.436 | Test: 0.454\n",
            "[Epoch 5/200] Loss: 1.5882065296173096 | Val: 0.476 | Test: 0.488\n",
            "[Epoch 6/200] Loss: 1.5036145448684692 | Val: 0.524 | Test: 0.529\n",
            "[Epoch 7/200] Loss: 1.4088826179504395 | Val: 0.546 | Test: 0.558\n",
            "[Epoch 9/200] Loss: 1.1889865398406982 | Val: 0.564 | Test: 0.593\n",
            "[Epoch 10/200] Loss: 1.1160939931869507 | Val: 0.576 | Test: 0.601\n",
            "[Epoch 11/200] Loss: 1.068234920501709 | Val: 0.628 | Test: 0.636\n",
            "[Epoch 12/200] Loss: 0.9679907560348511 | Val: 0.660 | Test: 0.669\n",
            "[Epoch 13/200] Loss: 0.8586306571960449 | Val: 0.684 | Test: 0.691\n",
            "[Epoch 14/200] Loss: 0.7883113026618958 | Val: 0.708 | Test: 0.725\n",
            "[Epoch 15/200] Loss: 0.7423396706581116 | Val: 0.736 | Test: 0.745\n",
            "[Epoch 16/200] Loss: 0.6636909246444702 | Val: 0.742 | Test: 0.760\n",
            "[Epoch 17/200] Loss: 0.614224374294281 | Val: 0.758 | Test: 0.770\n",
            "[Epoch 18/200] Loss: 0.5892379879951477 | Val: 0.760 | Test: 0.773\n",
            "[Epoch 19/200] Loss: 0.48813754320144653 | Val: 0.762 | Test: 0.776\n",
            "[Epoch 21/200] Loss: 0.42724230885505676 | Val: 0.764 | Test: 0.778\n",
            "[Epoch 22/200] Loss: 0.3682929277420044 | Val: 0.768 | Test: 0.776\n",
            "[Epoch 23/200] Loss: 0.33081382513046265 | Val: 0.770 | Test: 0.778\n",
            "[Epoch 24/200] Loss: 0.25971049070358276 | Val: 0.772 | Test: 0.782\n",
            "[Epoch 172/200] Loss: 0.04621141776442528 | Val: 0.774 | Test: 0.811\n",
            "[Epoch 200/200] Loss: 0.03871951997280121 | Val: 0.764 | Test: 0.816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPytNhU99yr-",
        "outputId": "35c7432d-1652-4e57-d5ce-d033d796575e"
      },
      "source": [
        "        \n",
        "model_cit = GCN(nfeat = Citeseer.num_features, nhid = 16, nclass = Citeseer.num_classes, dropout = 0.5)\n",
        "\n",
        "train(model_cit, data = Citeseer[0] , num_epochs = 200)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/200] Loss: 1.9599077701568604 | Val: 0.246 | Test: 0.246\n",
            "[Epoch 2/200] Loss: 1.7302590608596802 | Val: 0.340 | Test: 0.342\n",
            "[Epoch 3/200] Loss: 1.5734277963638306 | Val: 0.398 | Test: 0.399\n",
            "[Epoch 4/200] Loss: 1.439060926437378 | Val: 0.452 | Test: 0.457\n",
            "[Epoch 5/200] Loss: 1.2783361673355103 | Val: 0.494 | Test: 0.514\n",
            "[Epoch 6/200] Loss: 1.1819312572479248 | Val: 0.534 | Test: 0.545\n",
            "[Epoch 7/200] Loss: 1.0653191804885864 | Val: 0.570 | Test: 0.576\n",
            "[Epoch 8/200] Loss: 0.9066251516342163 | Val: 0.592 | Test: 0.600\n",
            "[Epoch 9/200] Loss: 0.8510716557502747 | Val: 0.616 | Test: 0.608\n",
            "[Epoch 10/200] Loss: 0.7160793542861938 | Val: 0.622 | Test: 0.619\n",
            "[Epoch 11/200] Loss: 0.6603959202766418 | Val: 0.626 | Test: 0.631\n",
            "[Epoch 13/200] Loss: 0.5386476516723633 | Val: 0.632 | Test: 0.643\n",
            "[Epoch 14/200] Loss: 0.45930805802345276 | Val: 0.636 | Test: 0.643\n",
            "[Epoch 15/200] Loss: 0.3511947691440582 | Val: 0.638 | Test: 0.647\n",
            "[Epoch 16/200] Loss: 0.37237781286239624 | Val: 0.642 | Test: 0.641\n",
            "[Epoch 18/200] Loss: 0.2597161531448364 | Val: 0.656 | Test: 0.637\n",
            "[Epoch 30/200] Loss: 0.10407606512308121 | Val: 0.664 | Test: 0.647\n",
            "[Epoch 31/200] Loss: 0.11719336360692978 | Val: 0.668 | Test: 0.650\n",
            "[Epoch 32/200] Loss: 0.12983568012714386 | Val: 0.670 | Test: 0.652\n",
            "[Epoch 33/200] Loss: 0.0921747237443924 | Val: 0.674 | Test: 0.652\n",
            "[Epoch 62/200] Loss: 0.04890159144997597 | Val: 0.676 | Test: 0.680\n",
            "[Epoch 148/200] Loss: 0.03979509696364403 | Val: 0.680 | Test: 0.683\n",
            "[Epoch 149/200] Loss: 0.046996235847473145 | Val: 0.684 | Test: 0.687\n",
            "[Epoch 150/200] Loss: 0.050010427832603455 | Val: 0.688 | Test: 0.686\n",
            "[Epoch 200/200] Loss: 0.03974771499633789 | Val: 0.680 | Test: 0.682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRR3e0uXAY-8"
      },
      "source": [
        "model_pub = GCN(nfeat = Pubmed.num_features, nhid = 16, nclass = Pubmed.num_classes, dropout = 0.5)\n",
        "\n",
        "train(model_pub, data = Pubmed[0] , num_epochs = 200)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4zDxUDwA5nf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}